{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageBot\n",
    "\n",
    "This notebook shows how to use the ImageBot API to ingest or generate images from text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Ingestion\n",
    "\n",
    "For image ingestion, we will use the `SimpleBot` class, which can take an iterable of messages and pass them to the LLM.  Making one of the messages an image URL or a local file path will automatically convert it into a format that can be used by the LLM.\n",
    "\n",
    "In this example, we will use a local LLM (Gemma 3n) hosted on LM Studio on an Apple Silicon Mac.  You can choose any LLM that is compatible with your computer architecture (including non-local models) as long as they can process images.\n",
    "\n",
    "First you need to set up the environment variable to point to your LM Studio instance.  You can skip this step if you are using a non-local model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API base (for LM Studio), API key, and model name\n",
    "#\n",
    "# NOTE: If you are using another service with a real API key,\n",
    "# you should NOT store it in plain text here. You should probably\n",
    "# use environment variables to manage sensitive information.\n",
    "API_BASE = \"http://localhost:1234/v1\"\n",
    "API_KEY = \"lm-studio\"  # This is a dummy value to bypass the check\n",
    "MODEL_NAME = \"lm_studio/gemma-3n-e4b-it-mlx\"\n",
    "\n",
    "# Define the temperature for the model's responses\n",
    "TEMPERATURE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a `SimpleBot` instance and connect to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llamabot as lmb\n",
    "from llamabot import SimpleBot\n",
    "from pathlib import Path\n",
    "\n",
    "# This example code was written and tested on an Apple Silicon Mac\n",
    "# using the LM Studio application to host a Gemma 3n model downloaded\n",
    "# from Hugging Face:\n",
    "# https://huggingface.co/lmstudio-community/gemma-3n-E4B-it-MLX-bf16\n",
    "#\n",
    "# Use lm_studio/ prefix to access local models through LM Studio.\n",
    "# You can also use other models (e.g. OpenAI or Ollama models)\n",
    "# as long as they support image inputs.  See the documentation for details.\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant that can analyze images and \n",
    "provide detailed descriptions of those images.  You will also try to answer\n",
    "any questions about the images to the best of your ability.\"\"\"\n",
    "\n",
    "bot = SimpleBot(\n",
    "    system_prompt,\n",
    "    temperature=TEMPERATURE,\n",
    "    api_base=API_BASE,\n",
    "    api_key=API_KEY,\n",
    "    model_name=MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the bot to process a message that includes an image.  We can do this by passing a list of messages to the bot, one of which is an image file path. The image we will use is shown below:\n",
    "\n",
    "![Bearly There](./Bearly_There.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the bot to describe an image localed at the given path\n",
    "image_path = Path(\"./Bearly_There.JPG\")\n",
    "\n",
    "first_message = [\n",
    "    lmb.user(\"Briefly (in less than 25 words) describe the following image: \"),\n",
    "    lmb.user(image_path),\n",
    "]\n",
    "\n",
    "response = bot(first_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the previous cell properly ingested the image and passed it to the LLM.  The LLM then generated a response based on the image content.  However, when using `SimpleBot` the context is not saved, so we cannot ask follow-up questions about the image.  \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will FAIL because SimpleBot does not maintain context between\n",
    "# calls by default.  So the bot has no idea what \"the picture you just\n",
    "# looked at\" is.  It could completely hallucinate a response or lecture\n",
    "# you that it can't see any picture.\n",
    "\n",
    "followup_message = [\n",
    "    lmb.user(\"Can you briefly describe the picture you just looked at?\"),\n",
    "]\n",
    "\n",
    "response2 = bot(followup_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can address this by creating a memory store for the chat which can hold the context of the conversation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a memory store for the chat which can hold the context of the\n",
    "# conversation.\n",
    "chat_memory = lmb.LanceDBDocStore(\n",
    "    table_name=\"img-chat-memory\",\n",
    ")\n",
    "chat_memory.reset()  # Clear any existing memory\n",
    "\n",
    "# Create a new bot that uses the memory store\n",
    "bot_with_memory = SimpleBot(\n",
    "    system_prompt,\n",
    "    temperature=TEMPERATURE,\n",
    "    api_base=API_BASE,\n",
    "    api_key=API_KEY,\n",
    "    model_name=MODEL_NAME,\n",
    "    chat_memory=chat_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can ask follow-up questions about the image and the bot will remember the context.  **NOTE**: You may need to increase the number of tokens the model can use to ensure it has enough context to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the bot to describe an image localed at the given path\n",
    "image_path = Path(\"./Bearly_There.JPG\")\n",
    "\n",
    "response = bot_with_memory(first_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can ask follow-up questions about the image and the bot will\n",
    "# remember the context.\n",
    "response2 = bot_with_memory(followup_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Generation\n",
    "\n",
    "Image generation, due to the rather large memory requirements, is normally not available on local models. We will need to use an visual language model, which is available through the OpenAI API. It is assumed you have set up your OpenAI API key in the environment variable (as per [OpenAI's best practices](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety) documentation).\n",
    "\n",
    "Once we have set up the environment variable, we can load the API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an OpenAI API Key from an environment variable and select an\n",
    "# OpenAI model to use\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# We will use the DALL-E 3 model for image generation, which is not\n",
    "# the newest model but is still quite capable.\n",
    "OPENAI_MODEL = \"dall-e-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llamabot.bot.imagebot import ImageBot\n",
    "\n",
    "# bot = ImageBot(\n",
    "#     api_key=OPENAI_API_KEY,\n",
    "#     model_name=OPENAI_MODEL,\n",
    "# )\n",
    "# bot(\"A siamese cat.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
