{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# What exactly makes an agent?\n",
    "\n",
    "Eric J. Ma\n",
    "\n",
    "PyData Boston/Cambridge, 29 Jan 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This talk is going to leave us with more questions than answers about \"what makes an agent\".\n",
    "\n",
    "But I hope it also leaves us with more focused questions and frameworks for thinking about \"what makes an agent\".\n",
    "\n",
    "It is based loosely on [my blog post](https://ericmjl.github.io/blog/2025/1/4/what-makes-an-agent/). After this talk, I will turn this into a new blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo\n",
    "import llamabot as lmb\n",
    "\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Let's start with LLM bots\n",
    "\n",
    "This is a helpful framing to anchor our discussion of agents.\n",
    "\n",
    "[LlamaBot](http://github.com/ericmjl/llamabot) implements a variety of LLM bots.\n",
    "\n",
    "LlamaBot is a Python package that I made to pedagogically explore the landscape of LLMs as the field evolves. Intentionally designed to lag 1-2 steps behind innovations and incorporate only what turns out to be robust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "The basic anatomy of an LLM API call:\n",
    "\n",
    "**1ï¸âƒ£ A system prompt:** maintained over all calls.\n",
    "\n",
    "**2ï¸âƒ£ A model name:** specifying which model to chat with.\n",
    "\n",
    "**3ï¸âƒ£ A user's prompt:** your input into the LLM's internals.\n",
    "\n",
    "**4ï¸âƒ£ The response:** returned by autoregressive next-token prediction.\n",
    "\n",
    "These are incorporated in `SimpleBot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_bot = lmb.SimpleBot(\n",
    "    system_prompt=\"\"\"You are a helpful travel assistant.\n",
    "    You provide information about flights between cities.\"\"\",\n",
    "    model_name=\"ollama_chat/llama3.2:3b\",\n",
    ")\n",
    "\n",
    "# Simple interaction\n",
    "response = flight_bot(\"Find me the prices for flights from San Francisco to Tokyo.\")\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Let's evaluate that response together. Is this an agent?\n",
    "\n",
    "**Audience commentary:**\n",
    "\n",
    "- Not an agent: didn't take action apart from introspection of weights.\n",
    "- Not an agent: no external APIs called.\n",
    "- Yes: agent doesn't mean it has to have a tool, anything that gives usable information is an agent.\n",
    "- Yes (to an extent): Follows up with a question/prompt back to the human.\n",
    "- No: agent should make decisions. This LLM call did not make any decisions. Decision-making outsourced to user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "`SimpleBot`s are heavily reliant on what's in the training data; they are just calling the LLM directly, with no memory of historical chat information. Given the range of regular human experiences in North America, I would venture to guess that it is rare for us to go outside of any base LLM's training data, unless we hit very specialized and niche topics not covered on the internet. (Try thinking of some!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Agents that give us structure?\n",
    "\n",
    "Let's try a different view of agents. What if we said, \"Agents give you information structured the way you wanted it?\" Let's start with that as a working definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "LlamaBot implements structured generation. To use it, you need to provide a Pydantic model, effectively a form that you want the bot to fill, and pair it with a `StructuredBot`. `StructuredBot`s have the same basic requirements as `SimpleBot`s, which are a system prompt and model name, but also need to have a Pydantic model passed in. When called, it will return an instance of that Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class FlightInfo(BaseModel):\n",
    "    origin: str\n",
    "    destination: str\n",
    "    duration: float = Field(..., description=\"Duration in hours\")\n",
    "    price: float = Field(..., description=\"Price in USD\")\n",
    "    recommended_arrival: float = Field(\n",
    "        ...,\n",
    "        description=\"Recommended time to arrive at airport before flight, in hours\",\n",
    "    )\n",
    "\n",
    "flight_bot_structured = lmb.StructuredBot(\n",
    "    system_prompt=\"\"\"You are a helpful travel assistant that provides\n",
    "    structured information about flights.\"\"\",\n",
    "    model_name=\"ollama_chat/llama3.2:3b\",\n",
    "    pydantic_model=FlightInfo,\n",
    ")\n",
    "\n",
    "# Now we get structured data\n",
    "result = flight_bot_structured(\n",
    "    \"Find me the prices for flights from San Francisco to Tokyo.\"\n",
    ")\n",
    "print()\n",
    "print(\"##########\")\n",
    "print(\n",
    "    f\"The price of the flight is ${result.price}. We recommend that you arrive at the airport {result.recommended_arrival} hours before the flight.\"\n",
    ")\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Audience discussion: Is this an agent?\n",
    "\n",
    "Where does this fall short of an agent's definition?\n",
    "\n",
    "- No: still like RAG. Doesn't read the situation, is this a good time to buy? Still a simple answer.\n",
    "- No: it would independent, independently decide what to look at, where to look.\n",
    "- Yes: Based on the working definition, yes, and the nature of decision-making means the LLM is doing rapid-fire retrieval from memorized data. Recommended arrival time **is** an added recommendation that was not part of the original query intent.\n",
    "- No: Is the definition even correct? Why isn't a SQL query an agent, under that definition?\n",
    "- No: within this context, the **latent** query intent might be to buy tix, but this bot doesn't help me do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Structured generation gets us midway\n",
    "\n",
    "It affords us more **control** over what we are asking an LLM to generate. The response is constrained.\n",
    "\n",
    "But it seems like it may still lack a crucial element of an \"agent\". I'm glad the audience shred up this definition! ðŸ¤—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## What if we said, \"An agent needed to interact externally\"?\n",
    "\n",
    "Here is my attempt, within LlamaBot, to try to nail down what an agent actually is. This flight agent-like bot helps me plan out trips, using one tool, the `search_internet` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamabot.bot.agentbot import search_internet\n",
    "\n",
    "travel_agent = lmb.AgentBot(\n",
    "    system_prompt=\"\"\"You are a travel planning assistant. Help users plan their trips\n",
    "    by searching flights, hotels, and checking weather.\"\"\",\n",
    "    functions=[search_internet],\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "# Now we can handle complex queries\n",
    "travel_response = travel_agent(\n",
    "    \"What's the flight time from San Francisco to Tokyo?\"\n",
    ")\n",
    "\n",
    "print(\"\\n##########\")\n",
    "print(travel_response.content)\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "If we got a straight answer, great!\n",
    "\n",
    "But if we didn't get a straight answer, that hints at some problems with agents, if they aren't designed properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Audience discussion: is this really an agent?\n",
    "\n",
    "I asked the audience to disregard the fact that I called this an `AgentBot`. Just because I said so doesn't make it so!\n",
    "\n",
    "Where are the holes in this definition of an agent?\n",
    "\n",
    "- Getting closer: agent will do research, in this example, it is the use of a search tool, and processing the text to give a response; the task could have been clearer for end user.\n",
    "- Yes: it has introduced a new error mode. A new way to be wrong, need someone to blame for this.\n",
    "- New component here: this bot has agency, decides \"do I call this function or not\".\n",
    "- Principal-Agent problem: agent does something that may not be what the Principal wanted it to do.\n",
    "\n",
    "More questions:\n",
    "\n",
    "- Q: Is part of the definition of an agent the fact that it is going to interact with a human?\n",
    "- Q: In this implementaiton of search, is the LLM always going to do the function call?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Design patterns: should this be an agent?\n",
    "\n",
    "We discussed what an agent is. Now, let's assume that we know what an agent is. (This is an assumption!) If so, how should we design agents, and even then, should it be an agent?\n",
    "\n",
    "Our minimally complex example is a restaurant bill calculator. It's got a few key characteristics:\n",
    "\n",
    "1. Bill calculation is computable (and hence easily verifiable).\n",
    "2. There is sufficient variation in the kinds of questions we can ask.\n",
    "3. We can easily implement multiple designs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### AgentBot implementation\n",
    "\n",
    "Let's start with an implementation based on AgentBot.\n",
    "\n",
    "We have two tools, which are nothing more than Python functions that are decorated with a `@tool` decorator. They are, namely, `calculate_total_with_tip` and `split_bill`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools\n",
    "@lmb.tool\n",
    "def calculate_total_with_tip(bill_amount: float, tip_rate: float) -> float:\n",
    "    if tip_rate < 0 or tip_rate > 1.0:\n",
    "        raise ValueError(\"Tip rate must be between 0 and 1.0\")\n",
    "    return bill_amount * (1 + tip_rate)\n",
    "\n",
    "@lmb.tool\n",
    "def split_bill(total_amount: float, num_people: int) -> float:\n",
    "    return total_amount / num_people\n",
    "\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Then, we create the AgentBot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bot\n",
    "bot = lmb.AgentBot(\n",
    "    system_prompt=lmb.system(\n",
    "        \"You are my assistant with respect to restaurant bills.\"\n",
    "    ),\n",
    "    functions=[calculate_total_with_tip, split_bill],\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Now, let's try a few calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total with tip\n",
    "calculate_total_only_prompt = (\n",
    "    \"My dinner was $2300 without tips. Calculate my total with an 18% tip.\"\n",
    ")\n",
    "resp = bot(calculate_total_only_prompt)\n",
    "print(resp.content)\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the bill\n",
    "split_bill_only_prompt = \"My dinner was $2300 in total, I added an 18% gratuity, split the bill between 20 people.\"\n",
    "resp2 = bot(split_bill_only_prompt)\n",
    "print(resp2.content)\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Couldn't it have been a Python function?\n",
    "\n",
    "Should this have been an agent?\n",
    "\n",
    "We very well could have done this instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bill(\n",
    "    total_amount: float, tip_percentage: int, num_people: int\n",
    ") -> float:\n",
    "    return (total_amount * (100 + tip_percentage) / 100) / num_people\n",
    "\n",
    "calculate_bill(2300, 18, 20)\n",
    "\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Is there a way to make that Python function more flexible?\n",
    "\n",
    "But this is a very restrictive implementation. What if we didn't have any division to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bill_v2(\n",
    "    total_amount: float, tip_percentage: int = 0, num_people: int = 1\n",
    ") -> float:\n",
    "    if tip_percentage:\n",
    "        total_amount = total_amount * (100 + tip_percentage) / 100\n",
    "    if num_people:\n",
    "        return total_amount / num_people\n",
    "    return total_amount\n",
    "\n",
    "calculate_bill_v2(2714, 0, 20)\n",
    "\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Same functionality, but with more flexibility. The scope of inputs is more variable, in the form of almost anything you want with natural language. And this point, by the way, seems to distinguish between an LLM agent and a Python program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### But couldn't reasoning models do this?\n",
    "\n",
    "What if we did this instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_bot = lmb.SimpleBot(\n",
    "    \"You are a smart bill calculator.\", model_name=\"ollama_chat/deepseek-r1:latest\"\n",
    ")\n",
    "r1_bot(\n",
    "    \"My dinner was $2300 in total, with 18% tip. Split the bill between 20 people. Respond with only the number.\"\n",
    ")\n",
    "\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### What if we didn't have to provide any tools instead?\n",
    "\n",
    "Or what if, we asked the agent to write and execute its own code? (This follows HuggingFace's definition of an agent.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamabot.bot.agentbot import write_and_execute_script\n",
    "\n",
    "# Create the bot\n",
    "autonomous_code_bot = lmb.AgentBot(\n",
    "    system_prompt=lmb.system(\n",
    "        \"You are my assistant with respect to restaurant bills.\"\n",
    "    ),\n",
    "    functions=[write_and_execute_script],\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "# Split the bill\n",
    "autonomous_code_bot(split_bill_only_prompt)\n",
    "mo.show_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Dissection\n",
    "\n",
    "If we think carefully about the distinction between a Python function, its stochastic variant, and an LLM agent, we might make the following observations:\n",
    "\n",
    "#### Functions\n",
    "\n",
    "1. Functions are written to accomplish a goal.\n",
    "1. Functions have an input signature, a body, and a return.\n",
    "2. Function inputs are constrained to the types that are accepted; they cannot be natural language.\n",
    "3. Function program flow is deterministic.\n",
    "\n",
    "#### Stochastic Functions\n",
    "\n",
    "1. Stochastic functions have non-deterministic flow control, resulting in a distribution of possible outputs.\n",
    "\n",
    "#### LLM Agents\n",
    "\n",
    "1. Are non-deterministic in flow control.\n",
    "2. Rely on structured outputs internally.\n",
    "3. Allow for natural language inputs.\n",
    "4. Nonetheless accomplish a goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### What should be an agent?\n",
    "\n",
    "Anthropic has [guidance](https://www.anthropic.com/research/building-effective-agents).\n",
    "\n",
    "> When building applications with LLMs, we recommend finding the simplest solution possible, and only increasing complexity when needed. **This might mean not building agentic systems at all.** Agentic systems often trade latency and cost for better task performance, and you should consider when this tradeoff makes sense.\n",
    ">\n",
    "> When more complexity is warranted, workflows offer predictability and consistency for well-defined tasks, whereas agents are the better option when flexibility and model-driven decision-making are needed at scale. For many applications, however, optimizing single LLM calls with retrieval and in-context examples is usually enough.\n",
    "\n",
    "In other words, can you build it with a regular Python program first? If so, maybe just start there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "And from my own blog:\n",
    "\n",
    "> ## A roadmap for designing agent applications\n",
    ">\n",
    "> I've found that the most effective way to design agent applications is to progressively relax constraints on inputs and execution order.\n",
    ">\n",
    "> ### Start with a deterministic program\n",
    ">\n",
    "> - Design your application as you would with regular API calls\n",
    "> - Define clear input/output specifications\n",
    "> - Implement core functionality with standard programming patterns\n",
    ">\n",
    "> ### Relax input constraints\n",
    ">\n",
    "> - Accept natural language input and convert it to structured parameters for function calls\n",
    "> - Enable autonomous function calling based on natural language understanding\n",
    ">\n",
    "> ### Relax execution order constraints\n",
    ">\n",
    "> - Only necessary when natural language inputs are varied enough to require different execution paths\n",
    "> - Allow flexible ordering of operations when needed\n",
    "> - Enable dynamic selection of which functions to call\n",
    "> - Maintain boundaries around available actions while allowing flexibility in their use\n",
    ">\n",
    "> This progressive relaxation approach helps us transition from traditional deterministic programming to an agent-driven paradigm where execution order is non-deterministic and inputs are natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## More perspectives\n",
    "\n",
    "- [Function calling is not solved](https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_function-calling-is-not-solved-yet-a-new-activity-7288821311613591552-i5dH?utm_source=share&utm_medium=member_desktop)\n",
    "- [Google's definition of agents](https://drive.google.com/file/d/1oEjiRCTbd54aSdB_eEe3UShxLBWK9xkt/view)\n",
    "- [HuggingFace's definition of agents](https://x.com/AymericRoucher/status/1874116324898598934)\n",
    "- [My blog post](https://ericmjl.github.io/blog/2025/1/4/what-makes-an-agent/)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
