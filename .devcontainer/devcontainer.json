{
    "name": "llamabot",
    "build": {
        "dockerfile": "Dockerfile",
        "context": ".."
    },
    "customizations": {
        "vscode": {
            "settings": {
                "python.defaultInterpreterPath": "/.pixi/envs/default/bin/python",
                "python.terminal.activateEnvironment": true,
                "python.terminal.activateEnvInCurrentTerminal": true,
            },
            "extensions": [
                "arcticicestudio.nord-visual-studio-code",
                "charliermarsh.ruff",
                "ms-azuretools.vscode-docker",
                "ms-python.python",
                "ms-python.vscode-pylance",
                "ms-toolsai.jupyter",
                "quarto.quarto",
                "redhat.vscode-yaml",
                "github.vscode-github-actions",
                "GitHub.codespaces",
                "GitHub.vscode-pull-request-github",
                "DavidAnson.vscode-markdownlint",
                "johnpapa.vscode-peacock"
            ]
        }
    },
    "forwardPorts": [
        8888
    ],
    "postCreateCommand": "/.pixi/envs/default/bin/pre-commit install && /.pixi/envs/default/bin/python -m ipykernel install --user --name llamabot",
    "postStartCommand": "ollama serve"
}
